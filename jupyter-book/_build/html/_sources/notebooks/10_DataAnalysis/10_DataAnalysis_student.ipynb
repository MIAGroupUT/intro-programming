{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb5dc51",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    ":::{admonition} Learning goals\n",
    ":class: note\n",
    "After finishing this chapter, you are expected to be able to\n",
    "* import SciPy and use some of its functions\n",
    "* create and manipulate Pandas dataframes\n",
    "* import data in CSV format\n",
    "* process this data\n",
    "* write data to different file formats\n",
    ":::\n",
    "\n",
    "There are hundreds if not thousands of packages available for Python. In the final chapter of this manual, we'll introduce some additional commonly used Python packages, in addition to NumPy and Matplotlib which you have already used. We will show how to use SciPy to perform mathematics, how to use Pandas to represent data, and how to use Seaborn to make beautiful figures.\n",
    "\n",
    "In addition to these, there are many other packages with more specialized uses that we will not introduce here but which you'll probably encounter during your studies. Examples include\n",
    "- The [scikit-image](https://scikit-image.org/) package offers a lot of functionality in image analysis.\n",
    "- The [scikit-learn](https://scikit-learn.org/) package provides tools for machine learning.\n",
    "- The [PyTorch](https://pytorch.org) package lets you build and train neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d4283",
   "metadata": {},
   "source": [
    "## SciPy\n",
    "SciPy provides algorithms for many mathematical problems like optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems. It uses NumPy arrays (which you already have used) for most of these things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41c5b",
   "metadata": {},
   "source": [
    ":::{admonition} Read the docs\n",
    ":class: note\n",
    "As always, we cannot mention all possible functionality. To grasp everything what you can do with SciPy, take a look at the [documentation](https://docs.scipy.org/doc/scipy/).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e044b2",
   "metadata": {},
   "source": [
    "SciPy works similarly to NumPy. It is a package, and its code is organized in multiple different modules. There is a module for optimization, for differential equations, etc. To import a module, the convention is to use `from scipy import <module_name>`. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage # This import the SciPy module that lets you work with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29957cb7",
   "metadata": {},
   "source": [
    "The `ndimage` module allows you to work with images. It contains many different kinds of filters (that let you change an image) and operations on images. For example, take a look at the `rotate` function [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.rotate.html#scipy.ndimage.rotate). It lets you rotate an image by a prespecified angle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cea22d",
   "metadata": {},
   "source": [
    ":::::{tab-set}\n",
    "\n",
    "::::{tab-item} English\n",
    "\n",
    ":::{admonition} Exercise 10.1\n",
    ":class: tip\n",
    "1. Download [this image file](https://surfdrive.surf.nl/files/index.php/s/3cfwvXJptwAJhwd).\n",
    "2. Load the image file using the `imageio` package as follows\n",
    "```python\n",
    "import imageio\n",
    "\n",
    "image = imageio.imread('art.jpeg')\n",
    "``` \n",
    "3. Show the image using Matplotlib's `imshow` function, give the figure a descriptive title.\n",
    "4. Rotate the image by 90 degrees using Scipy.\n",
    "5. Visualize the rotated image using Matplotlib, give the figure a decriptive title. \n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::::{tab-item} Nederlands\n",
    "\n",
    ":::{admonition} Opdracht 11.1\n",
    ":class: tip\n",
    "\n",
    "1. Download [dit bestand](https://surfdrive.surf.nl/files/index.php/s/3cfwvXJptwAJhwd) dat een plaatje bevat.\n",
    "2. Laad het plaatje in Python met behulp van de `imageio` package, als volgt\n",
    "```python\n",
    "import imageio\n",
    "\n",
    "image = imageio.imread('art.jpeg')\n",
    "``` \n",
    "3. Bekijk het plaatje met Matplotlib's `imshow` functie (zoals in Hoofdstuk 8). Geef de figuur een goede titel. \n",
    "4. Roteer het plaatje 90 graden met behulp van Scipy.\n",
    "5. Bekijk het geroteerde plaatje met Matplotlib. Geef de figuur weer een goede titel. \n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea5239",
   "metadata": {},
   "source": [
    "Another useful Scipy module is the `integrate` module that lets you numerically integrate functions in a given range. For this, we need to explain one important thing. Remember in Chapter 7 when we told you that everything in Python is an object? Well, even functions are actually objects. We can define the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968643f",
   "metadata": {},
   "source": [
    "and use it like we have used functions so far, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "square(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d0110",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975253ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "square(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6779b9b",
   "metadata": {},
   "source": [
    "But we can also get the type of the function when we use its name without `( )`. E.g., "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(square)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fec151",
   "metadata": {},
   "source": [
    "and Python tells us it has type `function` (no surprises there). Now, if we refer to `square` in this way, we can also pass the function itself as an argument to other functions, and that is what happens when we use the SciPy integrate package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d93d7",
   "metadata": {},
   "source": [
    "For example, we can integrate our `square` function between $x=0$ and $x=4$, i.e., compute\n",
    "\n",
    "$$\\int_0^4x^2 dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb5c63",
   "metadata": {},
   "source": [
    "SciPy provides multiple ways to integrate. Here, we'll just use (an optimized version of) Gaussian quadrature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec19271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "integrate.quad(square, 0, 4) # Use quadrature to integrate function x2 (x**2) between 0 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e70892",
   "metadata": {},
   "source": [
    "Take a look a the function call and what is returned. The first return value is the result of the integral, the second the absolute error. We can verify that the answer is approximately correct by analytically computing the integral as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb57e5",
   "metadata": {},
   "source": [
    "$$\\int_0^4x^2 dx = \\frac{1}{3}4^3 - \\frac{1}{3}0^3 = \\frac{64}{3} \\approx 21.33$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c5032",
   "metadata": {},
   "source": [
    ":::::{tab-set}\n",
    "\n",
    "::::{tab-item} English\n",
    "\n",
    ":::{admonition} Exercise 10.2\n",
    ":class: tip\n",
    "Consider the function $y=\\sin(x)$. \n",
    "1. Plot this function between $x=0$ and $=\\pi$.\n",
    "2. Compute the integral between $x=0$ and $x=\\pi$ using Scipy.\n",
    "3. Verify that the answer is correct by computing the analytical gradient. \n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::::{tab-item} Nederlands\n",
    "\n",
    ":::{admonition} Opdracht 10.2\n",
    ":class: tip\n",
    "\n",
    "Gegeven de functie $y=\\sin(x)$.\n",
    "1. Plot de functie tussen $x=0$ en $x=\\pi$ met behulp van Matplotlib.\n",
    "2. Integreer de functie tussen $x=0$ en $x=\\pi$ met Scipy.\n",
    "3. Ga na dat het antwoord dat je krijgt klopt door zelf de integraal te berekenen.\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528eb4e9",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "The second library that we'll look into is the Pandas package. Pandas is a very popular library that lets you work with large tables or data files, which it represents as DataFrames. A DataFrame is used to store tabular data: data that has rows (from top to bottom) and columns (from left to right). This data can be diverse. Note that Pandas does not support data structures with more than two dimensions. An important difference between NumPy arrays and Pandas dataframes is that arrays have one data type (`dtype`) per array, while dataframes have one `dtype` per column. This makes them more versatile. Moreover, we can give labels to columns, which makes it easier to understand what exactly is in the DataFrame, and avoids mixing up of columns. \n",
    "\n",
    "The image below shows an example DataFrame. The DataFrame has five rows and five columns. Each row has an index label, which can be used to identify the row. Each column has a column label. In each column, there is one data type: the *Name* column contains strings, the *Age* column contains integers, the *Marks* column contains floating point numbers, the *Grade* and *Hobby* columns contain strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d1446",
   "metadata": {},
   "source": [
    "![df](https://pynative.com/wp-content/uploads/2021/02/dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e22fb1",
   "metadata": {},
   "source": [
    ":::{admonition} Series\n",
    ":class: note\n",
    "Pandas also contains the `Series` class, which is similar to a DataFrame but only supports 1D arrays. Because DataFrames are much more commonly used, we will here focus on DataFrames.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65abe2",
   "metadata": {},
   "source": [
    "Just like other packages, Pandas needs to be imported into Python. We import Pandas as follows. Here, `pd` is an alias for the `pandas` package name that is widely used (just like `np` is short for `numpy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d5ed2",
   "metadata": {},
   "source": [
    "To create a new DataFrame, we call its constructor (as you have learned in Chapter 7). The DataFrame constructor has three commonly used arguments:\n",
    "\n",
    "```python\n",
    "pd.DataFrame(data=None, index=None, columns=None)\n",
    "```\n",
    "\n",
    "1. `data`: Here, you can use most of the data structures that you have seen so far: lists, NumPy arrays, dictionaries. For example, if we here provide a 2D NumPy array, columns in the DataFrame will correspond to columns in the array, and rows will correspond to rows (see example below).\n",
    "2. `index`: This defines how rows should be indexed. By default, this is just $0, 1, 2, \\ldots, n_{rows}-1$. \n",
    "3. `columns`: This defined how columns should be labeled. You can here provide, e.g., a list of strings. By default, this is just $0, 1, 2, \\ldots, n_{columns}-1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59f66a",
   "metadata": {},
   "source": [
    "As you can understand, there are many ways to construct a new DataFrame object. For example, we can initialize an object based on a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54192fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randint(0, 8, (5, 4)) # Create a random NumPy array\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D']) # Create a DataFrame based on the array, where column labels are A, B, C, D\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586183fb",
   "metadata": {},
   "source": [
    "We can also provide row indices using the `index` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=['Row 1', 'Row 2', 'Row 3', 'Row 4', 'Row 5'], columns=['A', 'B', 'C', 'D'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca822e51",
   "metadata": {},
   "source": [
    "We can also initialize a DataFrame using a dictionary. The dictionary keys will then be used as column labels, and the dictionary values will be used to fill the columns. For example, the code below creates a DataFrame that contains names and ages. To initialize the dataframe, we provide a dictionary where the keys correspond to the column name and the values to the values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "names = ['Mila', 'Mette', 'Tycho', 'Mike', 'Valentijn', \n",
    "         'Fay', 'Phileine', 'Sem', 'Selena', 'Dion'] # Make a list of names\n",
    "ages = np.random.randint(18, 80, len(names))         # Make a list of ages\n",
    "\n",
    "df = pd.DataFrame(data={'Names': names, 'Ages': ages}) # Initialize a DataFrame with columns 'Names' and 'Ages'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9c065",
   "metadata": {},
   "source": [
    "## Inspecting a Pandas DataFrame\n",
    "Pandas DataFrames can be very large. There are several ways to quickly check what's in them. The `head` method will list only the first few rows in a dataframe, and the `tail` method only the last few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8d339",
   "metadata": {},
   "source": [
    "Optionally, you can add an index to `head` or `tail` to show only the rows up to some index, or starting at some index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964898ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63610e6f",
   "metadata": {},
   "source": [
    "The `info` method provides a summary of the columns and data types (dtypes) in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b6775",
   "metadata": {},
   "source": [
    "You can also use the `describe` method to get a description of all numerical columns including some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ea3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27cc46",
   "metadata": {},
   "source": [
    "## Indexing and slicing a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acfaee",
   "metadata": {},
   "source": [
    "Just as in a list or a NumPy array, we can use indexing and slicing to select specific rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[4:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187aefa",
   "metadata": {},
   "source": [
    "Similarly as in a NumPy array with advanced indexing (see Chapter 6), we can select rows that match a particular pattern. For example, to get the rows of all people older than 40 years, we can index the DataFrame with an array of booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a280973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Ages']>40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7117f",
   "metadata": {},
   "source": [
    "Although indexing and slicing in this way works, it is recommend that in Pandas you use the `loc` and `iloc` methods for indexing. Using `loc`, to select the same rows as above, we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85558afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Ages'] > 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01437a6a",
   "metadata": {},
   "source": [
    "We can also select a specific column using `loc`. For example, to get all the names of people younger than 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Ages'] < 40, 'Names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc341d",
   "metadata": {},
   "source": [
    "The `iloc` method works similarly, but just takes indices or ranges as inputs. For example, to get the age of the person in the fourth row, we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f1da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2f112",
   "metadata": {},
   "source": [
    "Here, we can use all indexing and slicing tricks we have seen so far. For example, to select every the age of every third person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e346fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2::3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443e824",
   "metadata": {},
   "source": [
    "## Editing a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f276f26",
   "metadata": {},
   "source": [
    "You can remove rows or columns by calling the `drop` method. Columns are removed by using their name, as in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Ages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8871f9c",
   "metadata": {},
   "source": [
    "and rows can be dropped by using their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90449e7",
   "metadata": {},
   "source": [
    "Here, you can also use a range to remove, e.g., every even row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a87869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(range(0, len(df), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b31ac",
   "metadata": {},
   "source": [
    "The `drop` function returns a new object with the rows or columns of your choosing dropped. This might be inefficient for very large DataFrames. In that case, you can use `inplace=True`, which drops columns and rows `in-place`, or in the DataFrame that the method is working on. Take a look at the following example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907acca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Names': names, 'Ages': ages})\n",
    "\n",
    "print('Original DataFrame')\n",
    "print(df.head())\n",
    "print('\\nOriginal DataFrame after drop with inplace=False')\n",
    "df.drop(columns=['Names'])\n",
    "print(df.head())\n",
    "print('\\nOriginal DataFrame after drop with inplace=True')\n",
    "df.drop(columns=['Names'], inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e233a06",
   "metadata": {},
   "source": [
    "In the last case, we've permanently dropped the `Names` column from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c31506",
   "metadata": {},
   "source": [
    "We can add rows to a dataframe using the `append` method. Make sure to set `ignore_index=True` so the new row will be assigned an index that matches the already existing indices in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Names': names, 'Ages': ages})\n",
    "df.append({'Names': 'Ivo', 'Ages': 55}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfeff0",
   "metadata": {},
   "source": [
    "To add multiple rows at the same time, it is recommended that you use the `concat` function of Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_new = ['Sebastiaan', 'Noëlle', 'Pien', 'Luke', 'Samuel', 'Jet', 'Louise', 'Noëlle', 'David', 'Abel']\n",
    "ages_new = np.random.randint(18, 80, len(names_new)) # Make a list of ages\n",
    "\n",
    "df_new = pd.DataFrame({'Names': names_new, 'Ages': ages_new})\n",
    "df = pd.concat([df, df_new], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b766b",
   "metadata": {},
   "source": [
    "Another nice thing in Pandas is that we can easily define new columns. For example, in the DataFrame above, we can add a column that simply contains whether someone is over 60 or not, a column that checks whether someone is the oldest person in the group, a column that checks whether someone is celebrating a lustrum etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Senior'] = df['Ages'] > 60\n",
    "df['Oldest'] = df['Ages'] == df['Ages'].max()\n",
    "df['Lustrum'] = df['Ages'] % 5 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28611f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0cf39",
   "metadata": {},
   "source": [
    "This makes it very easy and interpretable to work with datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce486011",
   "metadata": {},
   "source": [
    "## Sorting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8777b8",
   "metadata": {},
   "source": [
    "We can sort a DataFrame according to one of its colums. For example, we can sort all rows alphabetically by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6403e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values('Names'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1687f",
   "metadata": {},
   "source": [
    "or sort by age, in descending or ascending order. For example, to get the four youngest people in the list, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values('Ages', ascending=True)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df7eb2",
   "metadata": {},
   "source": [
    ":::{admonition} Exercise 6.7 revisited\n",
    ":class: note\n",
    "Consider the `grades.npy` file in Exercise 6.7. Using Pandas, with a few lines of Python we can address all questions in that exercise. First, we create a DataFrame \n",
    "\n",
    "```python\n",
    "grades = np.load('grades.npy')\n",
    "df = pd.DataFrame(data=grades, columns=['Exam', 'Resit'])\n",
    "```\n",
    "\n",
    "Then, we answer the questions as follows:\n",
    "1. How many students are there in the class?\n",
    "```python\n",
    "len(df)\n",
    "```\n",
    "2. How many students passed the exam the first time (grade $\\geq 5.5$)?\n",
    "```python\n",
    "df['Passed'] = df['Exam'] >= 5.5  # Make a new column that says which students passed\n",
    "df['Passed'].sum()                # Count all True values\n",
    "```\n",
    "3. What was the average grade of students that passed the exam the first time?\n",
    "```python\n",
    "df.loc[df['Passed'], 'Exam'].mean() # Compute the average grade of those students that passed\n",
    "```\n",
    "4. Not all students that failed the exam, also took the resit. How many students didn't?\n",
    "```python\n",
    "df['No show'] = df['Resit'].isna() & ~df['Passed'] # Make a new column that contains the students that didn't take the resit (isna), and didnt't pass (the ~ is short for negative)\n",
    "df['No show'].sum()\n",
    "```\n",
    "\n",
    "In the end, the DataFrame `df` then looks like\n",
    "\n",
    "|    | Exam | Resit | Passed | Failed | No show |\n",
    "|---:|-----:|------:|-------:|-------:|--------:|\n",
    "|  0 |  3.0 |   6.2 |  False |   True |   False |\n",
    "|  1 |  6.5 |   NaN |   True |  False |   False |\n",
    "|  2 |  6.1 |   5.9 |   True |  False |   False |\n",
    "|  3 |  3.9 |   5.4 |  False |   True |   False |\n",
    "|  4 |  6.5 |   NaN |   True |  False |   False |\n",
    "|  5 |  1.3 |   6.4 |  False |   True |   False |\n",
    "|  6 |  7.4 |   NaN |   True |  False |   False |\n",
    "|  7 |  8.5 |   NaN |   True |  False |   False |\n",
    "|  8 |  1.8 |   NaN |  False |   True |    True |\n",
    "|  9 |  5.3 |   7.2 |  False |   True |   False |\n",
    "| 10 |  3.4 |   6.8 |  False |   True |   False |\n",
    "| 11 |  5.5 |   6.0 |   True |  False |   False |\n",
    "| 12 |  1.4 |   NaN |  False |   True |    True |\n",
    "| 13 |  5.4 |   7.2 |  False |   True |   False |\n",
    "| 14 |  4.6 |   5.0 |  False |   True |   False |\n",
    "| 15 |  6.3 |   NaN |   True |  False |   False |\n",
    "| 16 |  6.5 |   NaN |   True |  False |   False |\n",
    "| 17 |  4.0 |   NaN |  False |   True |    True |\n",
    "| 18 |  5.3 |   6.2 |  False |   True |   False |\n",
    "| 19 |  5.4 |   5.3 |  False |   True |   False |\n",
    "| 20 |  3.7 |   6.2 |  False |   True |   False |\n",
    "| 21 |  1.2 |   3.4 |  False |   True |   False |\n",
    "| 22 |  9.4 |   NaN |   True |  False |   False |\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ddd64",
   "metadata": {},
   "source": [
    "## Plotting Pandas data\n",
    "Pandas allows you to directly plot data from a DataFrame in a way that seemlessly integrates with Matplotlib. For example, to make a bar plot of all ages in our example DataFrame, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # Import matplotlib\n",
    "\n",
    "df = pd.DataFrame({'Names': names, 'Ages': ages}) # Create dataframe\n",
    "\n",
    "fig, ax = plt.subplots() # Create figure and axes \n",
    "df.plot(x='Names', y='Ages', ax=ax, kind='bar') # Plot directly from dataframe. Note that we provide the ax object as axes.\n",
    "ax.set_title('My first DataFrame plot'); # Add title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61d208",
   "metadata": {},
   "source": [
    "The `kind` argument lets you choose the kind of plot you want to make for a DataFrame. Take a look at the [`plot` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) to see which kinds of plots you can make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e2341",
   "metadata": {},
   "source": [
    "## Reading data to Pandas\n",
    "Pandas is able to read several useful file formats, the most common ones being CSV (comma-separated values) and Excel files. To read a CSV file, use `read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6246e7",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.read_csv(<filename>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e855e",
   "metadata": {},
   "source": [
    "Moreover, you can directly read Excel files using `pd.read_excel`. It could be that you have to install one additional package for that like `openpyxl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c52e22",
   "metadata": {},
   "source": [
    ":::::{tab-set}\n",
    "\n",
    "::::{tab-item} English\n",
    "\n",
    ":::{admonition} Exercise 10.3\n",
    ":class: tip\n",
    "\n",
    "1. Download a CSV file [here](https://surfdrive.surf.nl/files/index.php/s/phgNzlvJwA6rzog/download). \n",
    "2. Load this CSV file into a Pandas DataFrame.\n",
    "3. Inspect the contents of the DataFrame. The first column contains (if all is well) all last names in The Netherlands.\n",
    "4. How many times does your own last name occur?\n",
    "5. Find out what are the ten most common names in The Netherlands. Make a bar plot for the occurence of these names.\n",
    "6. See if you can find who among your fellow students has the most common last name.\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::::{tab-item} Nederlands\n",
    "\n",
    ":::{admonition} Opdracht 11.3\n",
    ":class: tip\n",
    "\n",
    "1. Download [hier](https://surfdrive.surf.nl/files/index.php/s/phgNzlvJwA6rzog/download) een CSV bestand. \n",
    "2. Laad dit CSV bestand in een Pandas DataFrame. \n",
    "3. Bekijk de inhoud van het DataFrame met de `inspect` en `info` methods. Bekijk de eerste paar rijen van het DataFrame. \n",
    "4. Het bestand bevat (als het goed is) alle achternamen in Nederland. Hoe vaak komt jouw achternaam voor?\n",
    "5. Wat zijn de tien meest voorkomende achternamen in Nederland? Maak een bar plot (staafdiagram) waarin je laat zien hoe vaak deze namen voorkomen.\n",
    "6. Wie van je studiegenoten heeft de meest voorkomende achternaam?\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45567aba",
   "metadata": {},
   "source": [
    ":::::{tab-set}\n",
    "\n",
    "::::{tab-item} English\n",
    "\n",
    ":::{admonition} Exercise 10.4\n",
    ":class: tip\n",
    "Download the CSV file [here](https://surfdrive.surf.nl/files/index.php/s/VVqhyQpZZhOcUj9). This file shows the cost of a Big Mac over time in 57 countries over a period of twenty years, from 2000 to 2020. \n",
    "\n",
    "![bigmac](https://s7d1.scene7.com/is/image/mcdonalds/ngk_gui_nl_main_big_mac:1-3-product-tile-desktop?wid=765&hei=472&dpr=off)\n",
    "\n",
    "1. Load this file into a Pandas DataFrame.\n",
    "2. Inspect the DataFrame.\n",
    "3. Use Matplotlib to plot the cost of a Big Mac in local currency in Denmark over time. Use the `date` column as your $x$-value. **Hint** Use `plt.xticks(rotation=70)` to rotate the time labels. \n",
    "4. The `dollar_price` column shows the cost of a Big Mac in dollars, also referred to as the [Big Mac Index](https://en.wikipedia.org/wiki/Big_Mac_Index). Find out which country has the most expensive Big Mac in 2020, and which country has the cheapest Big Mac. **Hint** Use `np.unique(df['name'])` to get all unique country names in the DataFrame.\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::::{tab-item} Nederlands\n",
    "\n",
    ":::{admonition} Opdracht 11.4\n",
    ":class: tip\n",
    "\n",
    "Download [hier](https://surfdrive.surf.nl/files/index.php/s/VVqhyQpZZhOcUj9) een CSV bestand. Dit bestand bevat de prijs van een Big Mac in 57 landen, in de periode van 2000 tot 2020.\n",
    "\n",
    "![bigmac](https://s7d1.scene7.com/is/image/mcdonalds/ngk_gui_nl_main_big_mac:1-3-product-tile-desktop?wid=765&hei=472&dpr=off)\n",
    "\n",
    "1. Laad het bestand in een Pandas DataFrame.\n",
    "2. Inspecteer het DataFrame om te kijken wat de kolommen betekenen.\n",
    "3. Gebruik Matplotlib om de prijs van een Big Mac in Denemarken Deense kronen tussen 2000 en 2020 te plotten. Gebruik hiervoor de `date` column als $x$-waarde. **Hint** Gebruik `plt.xticks(rotation=70)` om alle labels op de $x$-as een tikje te roteren.\n",
    "4. De `dollar_price` kolom bevat de waarde van een Big Mac in dollars. Dit wordt ook wel de [Big Mac-index](https://nl.wikipedia.org/wiki/Big_Mac-index) genoemd. Bepaal welk land de duurste Big Mac had in 2020, en welk land de goedkoopste. **Hint** Gebruik `np.unique(df['name'])` om een lijst unieke namen van landen te krijgen, en gebruik een `for`-loop om je antwoord te krijgen.\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9b37a",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "Seaborn provides a high-level plotting library that works seamlessly with Matplotlib. Take a look at the [Seaborn examples library](https://seaborn.pydata.org/examples/index.html) to see some of the things that you can do with Seaborn. By convention, we use Seaborn with an `sns` alias, i.e.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f10a60",
   "metadata": {},
   "source": [
    "Seaborn is the result of a perfect marriage between Matplotlib and Pandas. It naturally makes very informative figures of Pandas dataframes, and it is often sufficient to just mention which column you want to use in which role when making a figure. For example, consider the *Iris* dataset that you used in Chapter 8. This dataset can be loaded using the scikit-learn (or `sklearn`) package as below. Then, we make a DataFrame that contains that data, with the features in columns, and a column for the label of each flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris_data = datasets.load_iris() # Directly loads the Iris dataset into a dictionary iris_data\n",
    "\n",
    "df = pd.DataFrame(data=iris_data['data'], columns=iris_data['feature_names']) # Make a dataframe using dict\n",
    "df['species'] = iris_data['target_names'][iris_data['target']]                # Add a column for the target names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f0f82",
   "metadata": {},
   "source": [
    "Now using Seaborn, we can - in one line - make a [`pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html) for this data. This pairplot contains multiple scatter plots (one for each pair of features), and histograms (one for each feature). Individual flowers/samples are color-coded according to their label. You might recognize the bottom left figure as the one you created in Exercise 8.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue='species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a491b5",
   "metadata": {},
   "source": [
    "By default, Seaborn plots look quite pleasant. You can also style your plots by choosing a [color palette](https://seaborn.pydata.org/tutorial/color_palettes.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e209e",
   "metadata": {},
   "source": [
    ":::::{tab-set}\n",
    "\n",
    "::::{tab-item} English\n",
    "\n",
    ":::{admonition} Exercise 10.5\n",
    ":class: tip\n",
    "1. Get the `healthexp` dataset from Seaborn as follows\n",
    "```python\n",
    "df = sns.load_dataset('healthexp')\n",
    "```\n",
    "2. Inspect the data set using Pandas methods `head` and `describe`. What do you see in this data set? \n",
    "3. Use the Seaborn function [`lineplot`](https://seaborn.pydata.org/generated/seaborn.lineplot.html) to replicate the image below.\n",
    "![fig](https://surfdrive.surf.nl/files/index.php/s/4VuqEU2EjsPCgVl/download)\n",
    "4. Use Matplotlib, Pandas, or Seaborn to make a bar plot of spending per life years in 2020 as below. One solution is to first make a DataFrame with only rows relating to 2020. Note: Depending on the method that you use, the resulting figure will not match exactly.\n",
    "\n",
    "![fig](https://surfdrive.surf.nl/files/index.php/s/wOCDNdToXVW2Vgy/download)\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::::{tab-item} Nederlands\n",
    "\n",
    ":::{admonition} Opdracht 10.5\n",
    ":class: tip\n",
    "\n",
    "1. Maak een DataFrame op basis van de `healthexp` dataset in Seaborn, als volgt\n",
    "```python\n",
    "df = sns.load_dataset('healthexp')\n",
    "```\n",
    "2. Bekijk de data set met Pandas. Wat zie in je de dataset?\n",
    "3. Gebruik de Seaborn functie [`lineplot`](https://seaborn.pydata.org/generated/seaborn.lineplot.html) om zo goed mogelijk onderstaande figuur na te maken.\n",
    "\n",
    "![fig](https://surfdrive.surf.nl/files/index.php/s/4VuqEU2EjsPCgVl/download)\n",
    "4. Gebruik Matplotlib, Pandas, of Seaborn om een bar plot (staafdiagram) te maken van de uitgaven per levensjaar in 2020, zoals hieronder. Een mogelijke oplossing is om eerst alleen de data (rows) van 2020 te selecteren met `loc`. Afhankelijk van de methode die je kiest zal je figuur er waarschijnlijk net wat anders uitzien, dat is niet erg.\n",
    "\n",
    "![fig](https://surfdrive.surf.nl/files/index.php/s/wOCDNdToXVW2Vgy/download)\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
